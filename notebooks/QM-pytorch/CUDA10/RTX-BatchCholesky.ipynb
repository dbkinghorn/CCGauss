{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "import time\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device:  cuda:0\n",
      "PyTorch version:  0.4.1\n",
      "CUDA available:  True\n",
      "CUDA version:  9.0.176\n",
      "CUDA device: Graphics Device\n"
     ]
    }
   ],
   "source": [
    "dtype = th.float32\n",
    "\n",
    "gpuid = 0\n",
    "device = th.device(\"cuda:\"+ str(gpuid))\n",
    "#device = th.device(\"cpu\")\n",
    "\n",
    "print(\"Execution device: \",device)\n",
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)\n",
    "print(\"CUDA device:\", th.cuda.get_device_name(gpuid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# return the lower triangle of A in column order i.e. vech(A)\n",
    "def vech(A):\n",
    "    count = 0\n",
    "    c = A.shape[0]\n",
    "    v = th.zeros(c * (c + 1) // 2,)\n",
    "    for j in range(c):\n",
    "        for i in range(j,c):\n",
    "            v[count] = A[i,j]\n",
    "            count += 1\n",
    "    return th.tensor(v , device=device, dtype=dtype)\n",
    "\n",
    "# vech2L   create lower triangular matrix L from vechA\n",
    "def vech2L(v,n):\n",
    "    count = 0\n",
    "    L = th.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[i,j]=v[count]\n",
    "            count += 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)\n",
    "\n",
    "# batched vech2L input is \"X\" as V nb x n(n+1)/2\n",
    "def bvech2L(V,nb,n):\n",
    "    count = 0\n",
    "    L = th.zeros((nb,n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[...,i,j]=V[...,count]\n",
    "            count += 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4;\n",
    "nb=2;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "#npX = X.detach().numpy()\n",
    "L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "#for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "#    L[i][:,:] = vech2L(X[i,:],n)\n",
    "bL = bvech2L(X,nb,n)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "bA = th.matmul(bL,th.transpose(bL, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424, -0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832,  1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329, -0.0101,  0.0384, -0.1182]],\n",
       "\n",
       "        [[-1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [ 0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [ 1.1085,  0.2494, -1.5265, -0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0001, 0.1307], dtype=torch.float64)"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.prod(th.diagonal(bL, offset=0, dim1=-1, dim2=-2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0171, dtype=torch.float64)"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.prod(th.diag(bL[1]))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, dtype=torch.float64)"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.det(bL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0897,  0.0726,  0.0848, -0.0698],\n",
       "         [ 0.0726,  0.0601,  0.0301, -0.0561],\n",
       "         [ 0.0848,  0.0301,  1.1600, -0.0730],\n",
       "         [-0.0698, -0.0561, -0.0730,  0.0698]],\n",
       "\n",
       "        [[ 3.0435,  0.8190, -0.6845, -1.9338],\n",
       "         [ 0.8190,  0.9689,  0.5557, -0.3046],\n",
       "         [-0.6845,  0.5557,  0.9538,  0.2489],\n",
       "         [-1.9338, -0.3046,  0.2489,  3.7309]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0897,  0.0726,  0.0848, -0.0698],\n",
       "         [ 0.0726,  0.0601,  0.0301, -0.0561],\n",
       "         [ 0.0848,  0.0301,  1.1600, -0.0730],\n",
       "         [-0.0698, -0.0561, -0.0730,  0.0698]],\n",
       "\n",
       "        [[ 3.0435,  0.8190, -0.6845, -1.9338],\n",
       "         [ 0.8190,  0.9689,  0.5557, -0.3046],\n",
       "         [-0.6845,  0.5557,  0.9538,  0.2489],\n",
       "         [-1.9338, -0.3046,  0.2489,  3.7309]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424, -0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832,  1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329, -0.0101,  0.0384, -0.1182]],\n",
       "\n",
       "        [[-1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [ 0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [ 1.1085,  0.2494, -1.5265, -0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424, -0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832,  1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329, -0.0101,  0.0384, -0.1182]],\n",
       "\n",
       "        [[-1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [ 0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [ 1.1085,  0.2494, -1.5265, -0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7446,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4695,  0.8652,  0.0000,  0.0000],\n",
       "        [-0.3924,  0.8552,  0.2616,  0.0000],\n",
       "        [-1.1085,  0.2494, -1.5265,  0.3311]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.potrf(A[1], upper=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholA = th.zeros_like(A)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = th.potrf(A[i], upper=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424,  0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832, -1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329,  0.0101,  0.0384,  0.1182]],\n",
       "\n",
       "        [[ 1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [-0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [-1.1085,  0.2494, -1.5265,  0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky(A):\n",
    "    L = th.zeros_like(A)\n",
    "    \n",
    "    for i in range(A.shape[-1]):\n",
    "        for j in range(i+1):\n",
    "            s = 0.0\n",
    "            for k in range(j):\n",
    "                s = s + L[...,i,k].clone() * L[...,j,k].clone()\n",
    "            \n",
    "            L[...,i,j] = th.sqrt(A[...,i,i] - s) if (i == j) else \\\n",
    "                      (1.0 / L[...,j,j].clone() * (A[...,i,j] - s))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424,  0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832, -1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329,  0.0101,  0.0384,  0.1182]],\n",
       "\n",
       "        [[ 1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [-0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [-1.1085,  0.2494, -1.5265,  0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424,  0.0372,  0.0000,  0.0000],\n",
       "         [ 0.2832, -1.0352,  0.0895,  0.0000],\n",
       "         [-0.2329,  0.0101,  0.0384,  0.1182]],\n",
       "\n",
       "        [[ 1.7446,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4695,  0.8652,  0.0000,  0.0000],\n",
       "         [-0.3924,  0.8552,  0.2616,  0.0000],\n",
       "         [-1.1085,  0.2494, -1.5265,  0.3311]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholA = th.zeros_like(A)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = cholesky(A[i]) \n",
    "cholA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0897,  0.0726,  0.0848, -0.0698],\n",
       "        [ 0.0726,  0.0601,  0.0301, -0.0561],\n",
       "        [ 0.0848,  0.0301,  1.1600, -0.0730],\n",
       "        [-0.0698, -0.0561, -0.0730,  0.0698]], dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0897,  0.0726,  0.0848, -0.0698],\n",
       "         [ 0.0726,  0.0601,  0.0301, -0.0561],\n",
       "         [ 0.0848,  0.0301,  1.1600, -0.0730],\n",
       "         [-0.0698, -0.0561, -0.0730,  0.0698]],\n",
       "\n",
       "        [[ 3.0435,  0.8190, -0.6845, -1.9338],\n",
       "         [ 0.8190,  0.9689,  0.5557, -0.3046],\n",
       "         [-0.6845,  0.5557,  0.9538,  0.2489],\n",
       "         [-1.9338, -0.3046,  0.2489,  3.7309]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3;\n",
    "nb=100000;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "#npX = X.detach().numpy()\n",
    "L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "    L[i][:,:] = vech2L(X[i,:],n)\n",
    "#L = th.from_numpy(L)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "A = th.matmul(L,th.transpose(L, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.5366852283477783 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholA = th.zeros_like(A)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = th.potrf(A[i], upper=False) \n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.014220476150512695 seconds \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 3, 3])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholAout = cholesky(A)\n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "cholAout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU CUDA timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device:  cuda:0\n",
      "PyTorch version:  0.4.1\n",
      "CUDA available:  True\n",
      "CUDA version:  9.0.176\n",
      "CUDA device: TITAN V\n"
     ]
    }
   ],
   "source": [
    "dtype = th.float64\n",
    "\n",
    "gpuid = 0\n",
    "device = th.device(\"cuda:\"+ str(gpuid))\n",
    "#device = th.device(\"cpu\")\n",
    "\n",
    "print(\"Execution device: \",device)\n",
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)\n",
    "print(\"CUDA device:\", th.cuda.get_device_name(gpuid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3;\n",
    "nb=100000;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "#npX = X.detach().numpy()\n",
    "L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "    L[i][:,:] = vech2L(X[i,:],n)\n",
    "#L = th.from_numpy(L)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "A = th.matmul(L,th.transpose(L, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 156.54940176010132 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholA = th.zeros_like(A)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = th.potrf(A[i], upper=False) \n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.0039408206939697266 seconds \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 3, 3])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholAout = cholesky(A)\n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "cholAout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9576,  0.0000,  0.0000],\n",
       "        [-0.2829,  1.5446,  0.0000],\n",
       "        [ 1.1650, -0.6542,  0.2660]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholAout[5500,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.608506261721822"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.014220476150512695/0.0039408206939697266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39725.07604815778"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "156.54940176010132/0.0039408206939697266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 39.27142286300659 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholA = th.zeros_like(A)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = cholesky(A[i]) \n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big AKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device:  cpu\n",
      "PyTorch version:  0.4.1\n",
      "CUDA available:  True\n",
      "CUDA version:  9.0.176\n",
      "CUDA device: TITAN V\n"
     ]
    }
   ],
   "source": [
    "dtype = th.float64\n",
    "\n",
    "gpuid = 0\n",
    "#device = th.device(\"cuda:\"+ str(gpuid))\n",
    "device = th.device(\"cpu\")\n",
    "\n",
    "print(\"Execution device: \",device)\n",
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)\n",
    "print(\"CUDA device:\", th.cuda.get_device_name(gpuid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4;\n",
    "nb=4;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "#npX = X.detach().numpy()\n",
    "L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "    L[i][:,:] = vech2L(X[i,:],n)\n",
    "#L = th.from_numpy(L)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "A = th.matmul(L,th.transpose(L, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0897,  0.0726,  0.0848, -0.0698],\n",
       "         [ 0.0726,  0.5092,  0.5933, -1.2580],\n",
       "         [ 0.0848,  0.5933,  3.7483, -1.7689],\n",
       "         [-0.0698, -1.2580, -1.7689,  3.3608]],\n",
       "\n",
       "        [[ 0.1836,  0.0994, -0.4377, -0.3545],\n",
       "         [ 0.0994,  3.0612, -2.8244,  0.5386],\n",
       "         [-0.4377, -2.8244,  5.5334,  2.1298],\n",
       "         [-0.3545,  0.5386,  2.1298,  2.8615]],\n",
       "\n",
       "        [[ 0.0014, -0.0385,  0.0004, -0.0033],\n",
       "         [-0.0385,  2.5538,  0.5308,  0.4178],\n",
       "         [ 0.0004,  0.5308,  0.8569, -1.7871],\n",
       "         [-0.0033,  0.4178, -1.7871,  7.8861]],\n",
       "\n",
       "        [[ 0.9699, -0.4504,  1.9606,  0.2477],\n",
       "         [-0.4504,  1.2540, -1.0578, -1.7193],\n",
       "         [ 1.9606, -1.0578,  5.4200,  0.7207],\n",
       "         [ 0.2477, -1.7193,  0.7207,  2.5267]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKL = th.zeros((0,n,n), device=device, dtype=dtype)\n",
    "for i in range(nb):\n",
    "    AKL = th.cat( (AKL, th.add(A, A[i]))) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7947e-01,  1.4521e-01,  1.6967e-01, -1.3956e-01],\n",
       "         [ 1.4521e-01,  1.0184e+00,  1.1867e+00, -2.5161e+00],\n",
       "         [ 1.6967e-01,  1.1867e+00,  7.4966e+00, -3.5378e+00],\n",
       "         [-1.3956e-01, -2.5161e+00, -3.5378e+00,  6.7215e+00]],\n",
       "\n",
       "        [[ 2.7336e-01,  1.7197e-01, -3.5288e-01, -4.2428e-01],\n",
       "         [ 1.7197e-01,  3.5704e+00, -2.2311e+00, -7.1940e-01],\n",
       "         [-3.5288e-01, -2.2311e+00,  9.2817e+00,  3.6087e-01],\n",
       "         [-4.2428e-01, -7.1940e-01,  3.6087e-01,  6.2222e+00]],\n",
       "\n",
       "        [[ 9.1118e-02,  3.4091e-02,  8.5212e-02, -7.3108e-02],\n",
       "         [ 3.4091e-02,  3.0630e+00,  1.1242e+00, -8.4021e-01],\n",
       "         [ 8.5212e-02,  1.1242e+00,  4.6051e+00, -3.5560e+00],\n",
       "         [-7.3108e-02, -8.4021e-01, -3.5560e+00,  1.1247e+01]],\n",
       "\n",
       "        [[ 1.0596e+00, -3.7780e-01,  2.0454e+00,  1.7791e-01],\n",
       "         [-3.7780e-01,  1.7632e+00, -4.6450e-01, -2.9773e+00],\n",
       "         [ 2.0454e+00, -4.6450e-01,  9.1682e+00, -1.0482e+00],\n",
       "         [ 1.7791e-01, -2.9773e+00, -1.0482e+00,  5.8874e+00]],\n",
       "\n",
       "        [[ 2.7336e-01,  1.7197e-01, -3.5288e-01, -4.2428e-01],\n",
       "         [ 1.7197e-01,  3.5704e+00, -2.2311e+00, -7.1940e-01],\n",
       "         [-3.5288e-01, -2.2311e+00,  9.2817e+00,  3.6087e-01],\n",
       "         [-4.2428e-01, -7.1940e-01,  3.6087e-01,  6.2222e+00]],\n",
       "\n",
       "        [[ 3.6725e-01,  1.9872e-01, -8.7542e-01, -7.0899e-01],\n",
       "         [ 1.9872e-01,  6.1225e+00, -5.6488e+00,  1.0773e+00],\n",
       "         [-8.7542e-01, -5.6488e+00,  1.1067e+01,  4.2595e+00],\n",
       "         [-7.0899e-01,  1.0773e+00,  4.2595e+00,  5.7229e+00]],\n",
       "\n",
       "        [[ 1.8501e-01,  6.0846e-02, -4.3734e-01, -3.5783e-01],\n",
       "         [ 6.0846e-02,  5.6151e+00, -2.2936e+00,  9.5645e-01],\n",
       "         [-4.3734e-01, -2.2936e+00,  6.3903e+00,  3.4264e-01],\n",
       "         [-3.5783e-01,  9.5645e-01,  3.4264e-01,  1.0748e+01]],\n",
       "\n",
       "        [[ 1.1535e+00, -3.5104e-01,  1.5229e+00, -1.0680e-01],\n",
       "         [-3.5104e-01,  4.3152e+00, -3.8822e+00, -1.1807e+00],\n",
       "         [ 1.5229e+00, -3.8822e+00,  1.0953e+01,  2.8504e+00],\n",
       "         [-1.0680e-01, -1.1807e+00,  2.8504e+00,  5.3881e+00]],\n",
       "\n",
       "        [[ 9.1118e-02,  3.4091e-02,  8.5212e-02, -7.3108e-02],\n",
       "         [ 3.4091e-02,  3.0630e+00,  1.1242e+00, -8.4021e-01],\n",
       "         [ 8.5212e-02,  1.1242e+00,  4.6051e+00, -3.5560e+00],\n",
       "         [-7.3108e-02, -8.4021e-01, -3.5560e+00,  1.1247e+01]],\n",
       "\n",
       "        [[ 1.8501e-01,  6.0846e-02, -4.3734e-01, -3.5783e-01],\n",
       "         [ 6.0846e-02,  5.6151e+00, -2.2936e+00,  9.5645e-01],\n",
       "         [-4.3734e-01, -2.2936e+00,  6.3903e+00,  3.4264e-01],\n",
       "         [-3.5783e-01,  9.5645e-01,  3.4264e-01,  1.0748e+01]],\n",
       "\n",
       "        [[ 2.7681e-03, -7.7029e-02,  7.5042e-04, -6.6579e-03],\n",
       "         [-7.7029e-02,  5.1076e+00,  1.0616e+00,  8.3563e-01],\n",
       "         [ 7.5042e-04,  1.0616e+00,  1.7137e+00, -3.5742e+00],\n",
       "         [-6.6579e-03,  8.3563e-01, -3.5742e+00,  1.5772e+01]],\n",
       "\n",
       "        [[ 9.7128e-01, -4.8892e-01,  1.9610e+00,  2.4436e-01],\n",
       "         [-4.8892e-01,  3.8078e+00, -5.2701e-01, -1.3015e+00],\n",
       "         [ 1.9610e+00, -5.2701e-01,  6.2768e+00, -1.0664e+00],\n",
       "         [ 2.4436e-01, -1.3015e+00, -1.0664e+00,  1.0413e+01]],\n",
       "\n",
       "        [[ 1.0596e+00, -3.7780e-01,  2.0454e+00,  1.7791e-01],\n",
       "         [-3.7780e-01,  1.7632e+00, -4.6450e-01, -2.9773e+00],\n",
       "         [ 2.0454e+00, -4.6450e-01,  9.1682e+00, -1.0482e+00],\n",
       "         [ 1.7791e-01, -2.9773e+00, -1.0482e+00,  5.8874e+00]],\n",
       "\n",
       "        [[ 1.1535e+00, -3.5104e-01,  1.5229e+00, -1.0680e-01],\n",
       "         [-3.5104e-01,  4.3152e+00, -3.8822e+00, -1.1807e+00],\n",
       "         [ 1.5229e+00, -3.8822e+00,  1.0953e+01,  2.8504e+00],\n",
       "         [-1.0680e-01, -1.1807e+00,  2.8504e+00,  5.3881e+00]],\n",
       "\n",
       "        [[ 9.7128e-01, -4.8892e-01,  1.9610e+00,  2.4436e-01],\n",
       "         [-4.8892e-01,  3.8078e+00, -5.2701e-01, -1.3015e+00],\n",
       "         [ 1.9610e+00, -5.2701e-01,  6.2768e+00, -1.0664e+00],\n",
       "         [ 2.4436e-01, -1.3015e+00, -1.0664e+00,  1.0413e+01]],\n",
       "\n",
       "        [[ 1.9398e+00, -9.0081e-01,  3.9212e+00,  4.9539e-01],\n",
       "         [-9.0081e-01,  2.5080e+00, -2.1157e+00, -3.4386e+00],\n",
       "         [ 3.9212e+00, -2.1157e+00,  1.0840e+01,  1.4414e+00],\n",
       "         [ 4.9539e-01, -3.4386e+00,  1.4414e+00,  5.0533e+00]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(AKL.shape)\n",
    "AKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholAKL = cholesky(AKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4236,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3428,  0.9492,  0.0000,  0.0000],\n",
       "         [ 0.4005,  1.1056,  2.4726,  0.0000],\n",
       "         [-0.3294, -2.5319, -0.2453,  0.3774]],\n",
       "\n",
       "        [[ 0.5228,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3289,  1.8607,  0.0000,  0.0000],\n",
       "         [-0.6749, -1.0797,  2.7677,  0.0000],\n",
       "         [-0.8115, -0.2432, -0.1624,  2.3406]],\n",
       "\n",
       "        [[ 0.3019,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1129,  1.7465,  0.0000,  0.0000],\n",
       "         [ 0.2823,  0.6254,  2.0333,  0.0000],\n",
       "         [-0.2422, -0.4654, -1.5721,  2.9155]],\n",
       "\n",
       "        [[ 1.0294,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3670,  1.2761,  0.0000,  0.0000],\n",
       "         [ 1.9870,  0.2075,  2.2753,  0.0000],\n",
       "         [ 0.1728, -2.2834, -0.4034,  0.6934]],\n",
       "\n",
       "        [[ 0.5228,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3289,  1.8607,  0.0000,  0.0000],\n",
       "         [-0.6749, -1.0797,  2.7677,  0.0000],\n",
       "         [-0.8115, -0.2432, -0.1624,  2.3406]],\n",
       "\n",
       "        [[ 0.6060,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3279,  2.4525,  0.0000,  0.0000],\n",
       "         [-1.4446, -2.1101,  2.1278,  0.0000],\n",
       "         [-1.1699,  0.5957,  1.7983,  0.8749]],\n",
       "\n",
       "        [[ 0.4301,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1415,  2.3654,  0.0000,  0.0000],\n",
       "         [-1.0168, -0.9088,  2.1285,  0.0000],\n",
       "         [-0.8319,  0.4541, -0.0425,  3.1381]],\n",
       "\n",
       "        [[ 1.0740,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3268,  2.0514,  0.0000,  0.0000],\n",
       "         [ 1.4179, -1.6665,  2.4830,  0.0000],\n",
       "         [-0.0994, -0.5914,  0.8078,  2.0919]],\n",
       "\n",
       "        [[ 0.3019,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1129,  1.7465,  0.0000,  0.0000],\n",
       "         [ 0.2823,  0.6254,  2.0333,  0.0000],\n",
       "         [-0.2422, -0.4654, -1.5721,  2.9155]],\n",
       "\n",
       "        [[ 0.4301,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1415,  2.3654,  0.0000,  0.0000],\n",
       "         [-1.0168, -0.9088,  2.1285,  0.0000],\n",
       "         [-0.8319,  0.4541, -0.0425,  3.1381]],\n",
       "\n",
       "        [[ 0.0526,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.4641,  1.7217,  0.0000,  0.0000],\n",
       "         [ 0.0143,  0.6288,  1.1481,  0.0000],\n",
       "         [-0.1265,  0.3778, -3.3184,  2.1452]],\n",
       "\n",
       "        [[ 0.9855,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4961,  1.8872,  0.0000,  0.0000],\n",
       "         [ 1.9897,  0.2438,  1.5028,  0.0000],\n",
       "         [ 0.2480, -0.6245, -0.9366,  3.0140]],\n",
       "\n",
       "        [[ 1.0294,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3670,  1.2761,  0.0000,  0.0000],\n",
       "         [ 1.9870,  0.2075,  2.2753,  0.0000],\n",
       "         [ 0.1728, -2.2834, -0.4034,  0.6934]],\n",
       "\n",
       "        [[ 1.0740,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3268,  2.0514,  0.0000,  0.0000],\n",
       "         [ 1.4179, -1.6665,  2.4830,  0.0000],\n",
       "         [-0.0994, -0.5914,  0.8078,  2.0919]],\n",
       "\n",
       "        [[ 0.9855,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4961,  1.8872,  0.0000,  0.0000],\n",
       "         [ 1.9897,  0.2438,  1.5028,  0.0000],\n",
       "         [ 0.2480, -0.6245, -0.9366,  3.0140]],\n",
       "\n",
       "        [[ 1.3928,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.6468,  1.4456,  0.0000,  0.0000],\n",
       "         [ 2.8154, -0.2039,  1.6947,  0.0000],\n",
       "         [ 0.3557, -2.2196, -0.0074,  0.0064]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholAKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1795,  0.1452,  0.1697, -0.1396],\n",
       "        [ 0.1452,  1.0184,  1.1867, -2.5161],\n",
       "        [ 0.1697,  1.1867,  7.4966, -3.5378],\n",
       "        [-0.1396, -2.5161, -3.5378,  6.7215]], dtype=torch.float64)"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AKL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4236,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3428,  0.9492,  0.0000,  0.0000],\n",
       "        [ 0.4005,  1.1056,  2.4726,  0.0000],\n",
       "        [-0.3294, -2.5319, -0.2453,  0.3774]], dtype=torch.float64)"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholAKL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, dtype=torch.float64)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.det(AKL[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4077e-01, 3.9718e+01, 9.7672e+00, 4.2949e+00, 3.9718e+01, 7.6560e+00,\n",
       "        4.6182e+01, 1.3097e+02, 9.7672e+00, 4.6182e+01, 4.9771e-02, 7.0969e+01,\n",
       "        4.2949e+00, 1.3097e+02, 7.0969e+01, 4.7051e-04], dtype=torch.float64)"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detLKL = th.prod(th.diagonal(cholAKL, offset=0, dim1=-1, dim2=-2),1)**2\n",
    "detLKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 19.6909, -25.6447,  -0.9627,  -9.6974],\n",
       "        [-25.6447,  47.0616,   1.5875,  17.9196],\n",
       "        [ -0.9627,   1.5875,   0.2327,   0.6967],\n",
       "        [ -9.6974,  17.9196,   0.6967,   7.0220]], dtype=torch.float64)"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.potri(cholAKL[0], upper=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 19.6909, -25.6447,  -0.9627,  -9.6974],\n",
       "        [-25.6447,  47.0616,   1.5875,  17.9196],\n",
       "        [ -0.9627,   1.5875,   0.2327,   0.6967],\n",
       "        [ -9.6974,  17.9196,   0.6967,   7.0220]], dtype=torch.float64)"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.inverse(AKL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseL(L):\n",
    "    n = L.shape[-1]\n",
    "    invL = th.zeros_like(L)\n",
    "    for j in range(0,n):\n",
    "        invL[...,j,j] = 1.0/L[...,j,j]\n",
    "        for i in range(j+1,n):\n",
    "            s = 0.0\n",
    "            for k in range(i+1):\n",
    "                s -= L[...,i,k]*invL[...,k,j]\n",
    "            invL[...,i,j] = s/L[...,i,i]\n",
    "\n",
    "    return invL\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4236,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.3428,  0.9492,  0.0000,  0.0000],\n",
      "         [ 0.4005,  1.1056,  2.4726,  0.0000],\n",
      "         [-0.3294, -2.5319, -0.2453,  0.3774]],\n",
      "\n",
      "        [[ 0.5228,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.3289,  1.8607,  0.0000,  0.0000],\n",
      "         [-0.6749, -1.0797,  2.7677,  0.0000],\n",
      "         [-0.8115, -0.2432, -0.1624,  2.3406]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "M = cholAKL[0:2]\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 19.6909, -25.6447,  -0.9627,  -9.6974],\n",
       "         [-25.6447,  47.0616,   1.5875,  17.9196],\n",
       "         [ -0.9627,   1.5875,   0.2327,   0.6967],\n",
       "         [ -9.6974,  17.9196,   0.6967,   7.0220]],\n",
       "\n",
       "        [[  4.3084,  -0.0657,   0.1372,   0.2782],\n",
       "         [ -0.0657,   0.3377,   0.0775,   0.0301],\n",
       "         [  0.1372,   0.0775,   0.1312,   0.0107],\n",
       "         [  0.2782,   0.0301,   0.0107,   0.1825]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invLKL=inverseL(M)\n",
    "th.matmul(th.transpose(invLKL, 1, 2),invLKL)\n",
    "#th.matmul(th.t(invLKL),invLKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3084, -0.0657,  0.1372,  0.2782],\n",
       "        [-0.0657,  0.3377,  0.0775,  0.0301],\n",
       "        [ 0.1372,  0.0775,  0.1312,  0.0107],\n",
       "        [ 0.2782,  0.0301,  0.0107,  0.1825]], dtype=torch.float64)"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(15, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(15, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 204, in dispatch_shell\n",
      "    idents,msg = self.session.feed_identities(msg, copy=False)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/jupyter_client/session.py\", line 853, in feed_identities\n",
      "    raise ValueError(\"DELIM not in msg_list\")\n",
      "ValueError: DELIM not in msg_list\n",
      "Exception in callback BaseAsyncIOLoop._handle_events(15, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(15, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 204, in dispatch_shell\n",
      "    idents,msg = self.session.feed_identities(msg, copy=False)\n",
      "  File \"/home/kinghorn/anaconda3/envs/pytorch/lib/python3.6/site-packages/jupyter_client/session.py\", line 853, in feed_identities\n",
      "    raise ValueError(\"DELIM not in msg_list\")\n",
      "ValueError: DELIM not in msg_list\n"
     ]
    }
   ],
   "source": [
    " th.inverse(AKL[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. for k = 1 to n\n",
    "2.   X[k,k] = l/L[k,k]\n",
    "3.   for i = k+1 to n\n",
    "4.     X[i,k] = -L[i, k:i-1]*X[k:i-1,k]/L[i,i]\n",
    "5.   end for i\n",
    "6. end for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "j 1\n",
      "k 0\n",
      "i,j,k 0 1 0\n",
      "j 2\n",
      "k 0\n",
      "i,j,k 0 2 0\n",
      "i 1\n",
      "j 2\n",
      "k 0\n",
      "i,j,k 1 2 0\n",
      "k 1\n",
      "i,j,k 1 2 1\n",
      "i 2\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "for i in range(n):\n",
    "    print('i',i)\n",
    "    for j in range(i+1,n):\n",
    "        print('j',j)\n",
    "        for k in range(i+1):\n",
    "            print('k',k)\n",
    "            print('i,j,k',i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IJ structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3;\n",
    "nb=1000000;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "\n",
    "#L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "#for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "#    L[i][:,:] = vech2L(X[i,:],n)\n",
    "L = bvech2L(X,nb,n)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "A = th.matmul(L,th.transpose(L, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 3, 3])"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 3, 3])"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.08464717864990234 seconds \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 3, 3])"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholAout = cholesky(A)\n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "cholAout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIJ = th.reshape(A, (1000,1000,n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.08845806121826172 seconds \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1000, 3, 3])"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cholAout = cholesky(AIJ)\n",
    "\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "cholAout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 3])\n",
      "tensor([[[[   3.3383,    0.0000,    0.0000],\n",
      "          [  -3.4735,    4.2929,    0.0000],\n",
      "          [  -4.1914,    3.6855,    1.2792]],\n",
      "\n",
      "         [[   0.5586,    0.0000,    0.0000],\n",
      "          [  -3.6598,    3.7475,    0.0000],\n",
      "          [   7.1815,   -6.9258,    4.3128]]],\n",
      "\n",
      "\n",
      "        [[[  29.7390,    0.0000,    0.0000],\n",
      "          [   7.3784,    0.8407,    0.0000],\n",
      "          [ -59.0134,   -1.6254,    1.0450]],\n",
      "\n",
      "         [[  68.4055,    0.0000,    0.0000],\n",
      "          [-428.1763,   10.1317,    0.0000],\n",
      "          [ 273.4188,   -3.8425,    1.1510]]]], dtype=torch.float64)\n",
      "tensor([[[[   3.3383,   -3.4735,   -4.1914],\n",
      "          [   0.0000,    4.2929,    3.6855],\n",
      "          [   0.0000,    0.0000,    1.2792]],\n",
      "\n",
      "         [[   0.5586,   -3.6598,    7.1815],\n",
      "          [   0.0000,    3.7475,   -6.9258],\n",
      "          [   0.0000,    0.0000,    4.3128]]],\n",
      "\n",
      "\n",
      "        [[[  29.7390,    7.3784,  -59.0134],\n",
      "          [   0.0000,    0.8407,   -1.6254],\n",
      "          [   0.0000,    0.0000,    1.0450]],\n",
      "\n",
      "         [[  68.4055, -428.1763,  273.4188],\n",
      "          [   0.0000,   10.1317,   -3.8425],\n",
      "          [   0.0000,    0.0000,    1.1510]]]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.0777e+01, -3.0359e+01, -5.3614e+00],\n",
       "          [-3.0359e+01,  3.2012e+01,  4.7143e+00],\n",
       "          [-5.3614e+00,  4.7143e+00,  1.6362e+00]],\n",
       "\n",
       "         [[ 6.5281e+01, -6.3453e+01,  3.0972e+01],\n",
       "          [-6.3453e+01,  6.2010e+01, -2.9869e+01],\n",
       "          [ 3.0972e+01, -2.9869e+01,  1.8600e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.4214e+03,  1.0213e+02, -6.1671e+01],\n",
       "          [ 1.0213e+02,  3.3488e+00, -1.6986e+00],\n",
       "          [-6.1671e+01, -1.6986e+00,  1.0921e+00]],\n",
       "\n",
       "         [[ 2.6277e+05, -5.3887e+03,  3.1470e+02],\n",
       "          [-5.3887e+03,  1.1742e+02, -4.4227e+00],\n",
       "          [ 3.1470e+02, -4.4227e+00,  1.3248e+00]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholAout = cholesky(AIJ[0:2,0:2])\n",
    "print(cholAout.shape)\n",
    "invLKL=inverseL(cholAout)\n",
    "print(invLKL)\n",
    "print(th.transpose(invLKL, dim0=-2, dim1=-1))\n",
    "th.matmul(th.transpose(invLKL, dim0=-2, dim1=-1),invLKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4421.4311,  102.1262,  -61.6711],\n",
       "        [ 102.1262,    3.3488,   -1.6986],\n",
       "        [ -61.6711,   -1.6986,    1.0921]], dtype=torch.float64)"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.inverse(AIJ[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky2(A):\n",
    "    L = th.zeros_like(A)\n",
    "    \n",
    "    for i in range(A.shape[-1]):\n",
    "        for j in range(i+1):\n",
    "            s = 0.0\n",
    "            for k in range(j):\n",
    "                s = s + L[...,i,k].clone() * L[...,j,k].clone()\n",
    "            \n",
    "            L[...,i,j] = th.sqrt(A[...,i,i] - s) if (i == j) else \\\n",
    "                      (1.0 / L[...,j,j].clone() * (A[...,i,j] - s))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky3(A):\n",
    "    L = th.zeros_like(A)\n",
    "    n = A.shape[-1]\n",
    "    for i in range(n):\n",
    "        S = A[...,i,i]\n",
    "        for ip in range(i):\n",
    "            S = S - th.dot(L[...,i,ip].clone(),L[...,i,ip].clone())\n",
    "        L[...,i,i] = th.sqrt(S)\n",
    "        #print(A[...,i,i]/L[...,i,i])\n",
    "        for j in range(i,n):\n",
    "            S = A[...,j,i]\n",
    "            for ip in range(i):\n",
    "                S = S - th.dot(A[...,i,ip],A[...,j,ip])\n",
    "            L[...,j,i] = S/L[...,i,i].clone()                        \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4;\n",
    "nb=4;\n",
    "nn = int(n*(n+1)/2)\n",
    "\n",
    "th.manual_seed(42)\n",
    "x = th.randn(int(nb*n*(n+1)/2) , device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape non-linear variables for easier indexing\n",
    "X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "#npX = X.detach().numpy()\n",
    "L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "#for i in range(nb):\n",
    "    #L[i][np.tril_indices(n)]=npX[i,:]\n",
    "#    L[i][:,:] = vech2L(X[i,:],n)\n",
    "bL = bvech2L(X,nb,n)\n",
    "#detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "bA = th.matmul(bL,th.transpose(bL, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424,  0.6712,  0.0000,  0.0000],\n",
       "         [ 0.2832,  0.7818,  1.7484,  0.0000],\n",
       "         [-0.2329, -1.7903, -0.1735,  0.2668]],\n",
       "\n",
       "        [[ 0.4285,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2319,  1.7342,  0.0000,  0.0000],\n",
       "         [-1.0215, -1.4921,  1.5046,  0.0000],\n",
       "         [-0.8273,  0.4212,  1.2716,  0.6187]],\n",
       "\n",
       "        [[ 0.0372,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.0352,  1.2174,  0.0000,  0.0000],\n",
       "         [ 0.0101,  0.4446,  0.8118,  0.0000],\n",
       "         [-0.0895,  0.2671, -2.3465,  1.5169]],\n",
       "\n",
       "        [[ 0.9848,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4573,  1.0222,  0.0000,  0.0000],\n",
       "         [ 1.9908, -0.1442,  1.1983,  0.0000],\n",
       "         [ 0.2515, -1.5695, -0.0052,  0.0045]]],\n",
       "       dtype=torch.float64, grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 1437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3 = cholesky2(bA)\n",
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2996,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2424,  0.6712,  0.0000,  0.0000],\n",
       "         [ 0.2832,  0.7818,  1.7484,  0.0000],\n",
       "         [-0.2329, -1.7903, -0.1735,  0.2668]],\n",
       "\n",
       "        [[ 0.4285,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2319,  1.7342,  0.0000,  0.0000],\n",
       "         [-1.0215, -1.4921,  1.5046,  0.0000],\n",
       "         [-0.8273,  0.4212,  1.2716,  0.6187]],\n",
       "\n",
       "        [[ 0.0372,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.0352,  1.2174,  0.0000,  0.0000],\n",
       "         [ 0.0101,  0.4446,  0.8118,  0.0000],\n",
       "         [-0.0895,  0.2671, -2.3465,  1.5169]],\n",
       "\n",
       "        [[ 0.9848,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.4573,  1.0222,  0.0000,  0.0000],\n",
       "         [ 1.9908, -0.1442,  1.1983,  0.0000],\n",
       "         [ 0.2515, -1.5695, -0.0052,  0.0045]]],\n",
       "       dtype=torch.float64, grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky(bA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0469,  0.0379,  0.0443, -0.0365,  0.1051,  0.1224, -0.2802, -0.2737,\n",
       "          0.0272,  0.0418,  0.0671,  0.0363, -0.1599, -0.1295,  0.2714, -0.2335,\n",
       "          0.0659,  0.2355,  0.1990,  0.0968, -0.0058,  0.1620, -0.0016,  0.0140,\n",
       "         -0.1906, -0.0696, -0.0418, -0.1271,  0.3673, -0.2374, -0.1542,  0.0716,\n",
       "         -0.3116, -0.0394, -0.1600,  0.0226,  0.2457, -0.1876,  0.0008, -0.0007],\n",
       "        dtype=torch.float64),)"
      ]
     },
     "execution_count": 1429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc3 = th.norm(c3)\n",
    "th.autograd.grad(nc3,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn = th.norm(testf(bA))\n",
    "#fcn = th.norm(cholesky2(bA))\n",
    "cholA = th.zeros_like(bA)\n",
    "for i in range(nb):\n",
    "    cholA[i][:,:] = th.potrf(bA[i], upper=False) \n",
    "out = th.norm(cholA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0469,  0.0379,  0.0443, -0.0365,  0.1051,  0.1224, -0.2802, -0.2737,\n",
       "          0.0272,  0.0418,  0.0671,  0.0363, -0.1599, -0.1295,  0.2714, -0.2335,\n",
       "          0.0659,  0.2355,  0.1990,  0.0968, -0.0058,  0.1620, -0.0016,  0.0140,\n",
       "         -0.1906, -0.0696, -0.0418, -0.1271,  0.3673, -0.2374, -0.1542,  0.0716,\n",
       "         -0.3116, -0.0394, -0.1600,  0.0226,  0.2457, -0.1876,  0.0008, -0.0007],\n",
       "        dtype=torch.float64),)"
      ]
     },
     "execution_count": 1369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.autograd.grad(out,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseL(L):\n",
    "    n = L.shape[-1]\n",
    "    invL = th.zeros_like(L)\n",
    "    for j in range(0,n):\n",
    "        invL[...,j,j] = 1.0/L[...,j,j]\n",
    "        for i in range(j+1,n):\n",
    "            S = 0.0\n",
    "            for k in range(i+1):\n",
    "                S = S - L[...,i,k]*invL[...,k,j].clone()\n",
    "            invL[...,i,j] = S/L[...,i,i]\n",
    "\n",
    "    return invL\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.1133e-01,  4.0547e-01,  1.5221e-02,  1.5333e-01, -4.7854e-01,\n",
       "         -1.6699e-02, -1.8183e-01, -4.3710e-03, -5.4579e-02, -1.1752e+00,\n",
       "         -4.2422e-02,  3.1394e-03,  6.9645e-04, -6.3647e-03, -4.6774e-03,\n",
       "         -3.5370e-03,  4.3118e-03, -6.6674e-03,  3.4304e-03, -2.8498e-02,\n",
       "          1.2148e+02,  2.7574e+00, -3.7150e+00, -9.3669e-01,  2.3479e+00,\n",
       "         -3.1633e+00, -7.9761e-01,  1.7936e+00,  4.5211e-01,  7.8527e-01,\n",
       "          2.4009e+01,  8.2088e+01,  2.3072e-01,  5.3439e+01,  3.0724e+02,\n",
       "          8.7456e-01,  2.0002e+02, -2.7482e-01, -6.4286e+01,  9.2836e+04],\n",
       "        dtype=torch.float64),)"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invL = inverseL(c3)\n",
    "out = th.norm(invL)\n",
    "th.autograd.grad(out,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
