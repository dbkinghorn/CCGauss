{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "import time\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device:  cuda:0\n",
      "PyTorch version:  1.0.0\n",
      "CUDA available:  True\n",
      "CUDA version:  10.0.130\n",
      "CUDA device: Graphics Device\n"
     ]
    }
   ],
   "source": [
    "dtype = th.float32\n",
    "\n",
    "gpuid = 0\n",
    "device = th.device(\"cuda:\"+ str(gpuid))\n",
    "#device = th.device(\"cpu\")\n",
    "\n",
    "print(\"Execution device: \",device)\n",
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)\n",
    "print(\"CUDA device:\", th.cuda.get_device_name(gpuid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def vech2L(v,n):\n",
    "    count = 0\n",
    "    L = th.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[i,j]=v[count]\n",
    "            count = count + 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)\n",
    "\n",
    "# batched vech2L input is \"X\" as V nb x n(n+1)/2\n",
    "def bvech2L(V,nb,n):\n",
    "    count = 0\n",
    "    L = th.zeros((nb,n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[...,i,j]=V[...,count]\n",
    "            count = count + 1\n",
    "    return th.tensor(L, device=device, dtype=dtype) + th.tensor(th.eye(n), device=device, dtype=dtype)\n",
    "\n",
    "# Batched Cholesky decomp\n",
    "def cholesky(A):\n",
    "    L = th.zeros_like(A)\n",
    "    \n",
    "    for i in range(A.shape[-1]):\n",
    "        for j in range(i+1):\n",
    "            s = 0.0\n",
    "            for k in range(j):\n",
    "                s = s + L[...,i,k].clone() * L[...,j,k].clone()\n",
    "            \n",
    "            L[...,i,j] = th.sqrt(A[...,i,i] - s) if (i == j) else \\\n",
    "                      (1.0 / L[...,j,j].clone() * (A[...,i,j] - s))\n",
    "    return L\n",
    "\n",
    "# Batched inverse of lower triangular matrices \n",
    "def inverseL(L):\n",
    "    n = L.shape[-1]\n",
    "    invL = th.zeros_like(L)\n",
    "    for j in range(0,n):\n",
    "        invL[...,j,j] = 1.0/L[...,j,j]\n",
    "        for i in range(j+1,n):\n",
    "            S = 0.0\n",
    "            for k in range(i+1):\n",
    "                S = S - L[...,i,k]*invL[...,k,j].clone()\n",
    "            invL[...,i,j] = S/L[...,i,i]\n",
    "\n",
    "    return invL\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_energyrc(x,n,nb,Mass,Qmat,Sym,symc):\n",
    "    \n",
    "    nx = len(x);\n",
    "    nn = int(n*(n+1)/2);\n",
    "    nsym = len(symc);\n",
    "    \n",
    "    # extract linear coefs \"eigen vector\"\n",
    "    c = x[-nb:];\n",
    "    # reshape non-linear variables for easier indexing\n",
    "    X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "    \n",
    "    # generate tensor of lower triangular matrices from X\n",
    "    # these are the non-linear parameters of the basis set\n",
    "    L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "    L = bvech2L(X,nb,n)\n",
    "    \n",
    "    # get the determinates for L |L| is the product of diag elements\n",
    "    detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "    \n",
    "    # create the tensor of matrix products of the L matrices AKL = L x Ltranspose\n",
    "    AK = th.matmul(L,th.transpose(L, 1, 2))\n",
    "\n",
    "    \n",
    "    # Initialize H T V and S matrices\n",
    "    # H = T + V, we are solving (H-ES)c = 0 for E (energy)\n",
    "    H = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    S = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    T = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    V = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    \n",
    "\n",
    "    # outer loop is over symmetry terms, the matrices are summed over these sym terms\n",
    "    for k in range(0,nsym):\n",
    "        \n",
    "        P = Sym[k,:,:]\n",
    "        # symetry projection is applied only to \"ket\" this constructs AL\n",
    "        AL = th.matmul(th.t(P), th.matmul(AK,P))\n",
    "\n",
    "        # Akl = Ak + Al\n",
    "        AKL = th.zeros((nb,nb,n,n), device=device, dtype=dtype)\n",
    "        #for i in range(nb):\n",
    "        #    for j in range(nb):\n",
    "        #        #AKL[i,j] =  th.add(AK[i], AL[j])\n",
    "        #        AKL[i,j] =  AK[i] + AL[j]\n",
    "        AKL = AL.repeat((nb,1,1,1)) + th.transpose(AK.repeat((nb,1,1,1)), 0,1)\n",
    "        \n",
    "        # get the Cholesky decomp of all Akl martices\n",
    "        cholAKL = cholesky(AKL)\n",
    "        \n",
    "        # get determinates of AKL from diags |Akl|= |Lk|**2\n",
    "        detAKL = th.prod(th.diagonal(cholAKL, offset=0, dim1=-1, dim2=-2),-1)**2\n",
    "        \n",
    "        # compute inverses of lower tringular matrices in cholAKL\n",
    "        invLKL = inverseL(cholAKL)\n",
    "        \n",
    "        # inverses Akl^-1 = Lkl' x Lkl\n",
    "        invAKL = th.matmul(th.transpose(invLKL, dim0=-1, dim1=-2),invLKL)\n",
    "\n",
    "        # get terms needed for potential energy V\n",
    "        RIJ = th.zeros_like(invAKL, device=device, dtype=dtype);\n",
    "        # 1/rij i~=j\n",
    "        for j in range(0,n-1):\n",
    "            for i in range(j+1,n):\n",
    "                tmp2 = invAKL[...,i,i] + invAKL[...,j,j] - 2*invAKL[...,i,j];\n",
    "                RIJ[...,i,j] = th.rsqrt(tmp2)\n",
    "\n",
    "        # 1/rij i=j\n",
    "        for i in range(0,n):\n",
    "            RIJ[...,i,i] = th.rsqrt(invAKL[...,i,i])    \n",
    "\n",
    "        # MATRIX ELEMENTS\n",
    "        \n",
    "        # Overlap: (normalized)\n",
    "        # Skl = 2^3n/2 (||Lk|| ||Ll||/|AKL|)^3/2\n",
    "        SKL = 2**(n*1.5) * th.sqrt( th.pow(th.ger(detL, detL)/detAKL ,3) );\n",
    "\n",
    "        # Kinetic energy\n",
    "        #TKL = SKL*(6*th.trace(Mass@Ak@invAkl@Al)) = skl*(6*th.sum(Mass*(Ak@invAkl@Al)))\n",
    "\n",
    "        Tmat = th.zeros_like(invAKL)\n",
    "        #for i in range(nb):\n",
    "        #    for j in range(nb):\n",
    "        #        Tmat[i,j] = (AK[i]@invAKL[i,j]@AL[j])\n",
    "        Tmat = th.matmul(th.transpose(AK.repeat((nb,1,1,1)), 0,1), th.matmul(invAKL,AL))\n",
    "        TKL = 6*SKL*th.sum(Mass*Tmat, dim=(-2,-1))\n",
    "\n",
    "        # potential energy\n",
    "        TWOoSqrtPI = 1.1283791670955126 # 2/sqrt(pi)\n",
    "        \n",
    "        VKL = TWOoSqrtPI*SKL*th.sum(RIJ*Qmat, dim=(-2,-1))\n",
    "    \n",
    "        # accumulate matrices over sym terms\n",
    "        S = S + symc[k]*SKL\n",
    "        T = T + symc[k]*TKL\n",
    "        V = V + symc[k]*VKL\n",
    "        \n",
    "    # Hamiltonian\n",
    "    H = T + V\n",
    "    \n",
    "    # complete lower triangle of H and S\n",
    "    #for i in range(0,nb):\n",
    "    #    for j in range(i+1,nb):\n",
    "    #        H[j,i] = H[i,j]\n",
    "    #        S[j,i] = S[i,j]\n",
    "    #        #H[i,j] = H[j,i];\n",
    "    #        #S[i,j] = S[j,i];\n",
    "    H = th.triu(H,1)+th.t(th.triu(H))\n",
    "    S = th.triu(S,1)+th.t(th.triu(S))\n",
    "    # compute Rayleigh quotent (it is the smallest energy eigen value when minimized over c)\n",
    "    cHc = c@H@c;\n",
    "    cSc = c@S@c;\n",
    "    eng = cHc/cSc;\n",
    "    \n",
    "    return eng           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_energyrc(steps=1, num_basis=8, restart=True):\n",
    "    \n",
    "    #\n",
    "    # Li BO setup\n",
    "    #\n",
    "    n=3;\n",
    "    \n",
    "    Mass = th.tensor([[0.5, 0.0, 0.0],\n",
    "                     [0.0, 0.5, 0.0],\n",
    "                     [0.0, 0.0, 0.5]], device=device, dtype=dtype);\n",
    "    \n",
    "    Charge = th.tensor([-3, 1, 1, -3, 1, -3], device=device, dtype=dtype);\n",
    "    Charge = vech2L(Charge,n)\n",
    "    \n",
    "    # symmetry projection terms\n",
    "    Sym = th.zeros((6,3,3), device=device, dtype=dtype)\n",
    "    # (1)(2)(3)\n",
    "    Sym[0,:,:] = th.tensor([[1,0,0],[0,1,0],[0,0,1]], device=device, dtype=dtype);\n",
    "    # (12)\n",
    "    Sym[1,:,:] = th.tensor([[0,1,0],[1,0,0],[0,0,1]], device=device, dtype=dtype);\n",
    "    # (13)\n",
    "    Sym[2,:,:] = th.tensor([[0,0,1],[0,1,0],[1,0,0]], device=device, dtype=dtype);\n",
    "    # (23)\n",
    "    Sym[3,:,:] = th.tensor([[1,0,0],[0,0,1],[0,1,0]], device=device, dtype=dtype);\n",
    "    # (123)\n",
    "    Sym[4,:,:] = th.tensor([[0,1,0],[0,0,1],[1,0,0]], device=device, dtype=dtype);\n",
    "    # (132)\n",
    "    Sym[5,:,:] = th.tensor([[0,0,1],[1,0,0],[0,1,0]], device=device, dtype=dtype);\n",
    "\n",
    "    # coeff's\n",
    "    symc = th.tensor([4.0,4.0,-2.0,-2.0,-2.0,-2.0], device=device, dtype=dtype);\n",
    "\n",
    "    # Sample parameters should return energy of -7.3615\n",
    "    xvechL=th.tensor([\n",
    "         1.6210e+00, -2.1504e-01,  9.0755e-01,  9.7866e-01, -2.8418e-01,\n",
    "        -3.5286e+00, -3.3045e+00, -4.5036e+00, -3.2116e-01, -7.1901e-02,\n",
    "         1.5167e+00, -8.4489e-01, -2.1377e-01, -3.6127e-03, -5.3774e-03,\n",
    "        -2.1263e+00, -2.5191e-01,  2.1235e+00, -2.1396e-01, -1.4084e-03,\n",
    "        -1.0092e-02,  4.5349e+00,  9.4837e-03,  1.1225e+00, -2.1315e-01,\n",
    "         5.8451e-02, -4.9410e-03,  5.0853e+00,  7.3332e-01,  5.0672e+00,\n",
    "        -2.1589e-01, -6.8986e-03, -1.4310e-02,  1.5979e+00,  3.3946e-02,\n",
    "        -8.7965e-01, -1.1121e+00, -2.1903e-03, -4.6925e-02,  2.1457e-01,\n",
    "         3.3045e-03,  4.5120e+00, -2.1423e-01, -1.6493e-02, -2.3429e-03,\n",
    "        -8.6715e-01, -6.7070e-02,  1.5998e+00\n",
    "     ], device=device, dtype=dtype, requires_grad=False)\n",
    "\n",
    "    evec = th.tensor([\n",
    "      -6.0460e-02,  7.7708e-05, 1.6152e+00,  9.5443e-01,  \n",
    "      1.1771e-01,  3.2196e+00,  9.6344e-01, 3.1398e+00\n",
    "    ], device=device, dtype=dtype, requires_grad=False)\n",
    "\n",
    "    \n",
    "    # uncomment following lines to test above \n",
    "    #nb=8\n",
    "    #x1 = th.tensor(th.cat((xvechL,evec)), device=device, dtype=dtype, requires_grad=True)\n",
    "    #energy = b_energyrc(x1,n,nb,Mass,Charge,Sym,symc) \n",
    "    #print(energy) # should be -7.3615\n",
    "    #return x1\n",
    "    \n",
    "    if restart:\n",
    "        nb=num_basis\n",
    "        x1 = xrestart\n",
    "    else:\n",
    "        # random start point\n",
    "        nb=num_basis\n",
    "        #th.manual_seed(333)\n",
    "        x1 = th.empty(int(nb*n*(n+1)/2 + nb), device=device, dtype=dtype, requires_grad=True)\n",
    "        th.nn.init.uniform_(x1, a=-0.8, b=0.8)\n",
    "        \n",
    "    # start from a restart value\n",
    "    #x1 = xrestart\n",
    "    #print(energy)\n",
    "    #return x1\n",
    "    \n",
    "    # Do the Optimization\n",
    "    #optimizer = th.optim.LBFGS([x1])\n",
    "    #optimizer = th.optim.Adadelta([x1], lr=160.0)\n",
    "    #optimizer = th.optim.Adam([x1], lr=0.00005)\n",
    "    optimizer = th.optim.Rprop([x1], lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-07, 50))\n",
    "    \n",
    "    #scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(optimizer,threshold=0.00001,cooldown=3, verbose=True,patience=2, factor=0.5)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        loss = b_energyrc(x1,n,nb,Mass,Charge,Sym,symc)\n",
    "        loss.backward()\n",
    "        #def closure():\n",
    "        #    return b_energyrc(x1,n,nb,Mass,Charge,Sym,symc)\n",
    "        #optimizer.step(closure)\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "        \n",
    "        if (i<100 or not i%100):print('step: {:5}  f: {:4.12f}  gradNorm: {:.9f}'.format(i, loss, th.norm(x1.grad)))\n",
    "    # print last value\n",
    "    print('step: {:5}  f: {:4.12f}  gradNorm: {:.9f}'.format(i, loss, th.norm(x1.grad)))\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinghorn/anaconda3/envs/pytorch10/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/home/kinghorn/anaconda3/envs/pytorch10/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:     0  f: -6.969740390778  gradNorm: 0.002223858\n",
      "step:     1  f: -6.969743251801  gradNorm: 0.002192316\n",
      "step:     2  f: -6.969758510590  gradNorm: 0.001941136\n",
      "step:     3  f: -6.969770431519  gradNorm: 0.001668256\n",
      "step:     4  f: -6.969773769379  gradNorm: 0.001746491\n",
      "step:     5  f: -6.969790935516  gradNorm: 0.001489454\n",
      "step:     6  f: -6.969790458679  gradNorm: 0.001322002\n",
      "step:     7  f: -6.969811439514  gradNorm: 0.001279872\n",
      "step:     8  f: -6.969835758209  gradNorm: 0.001256723\n",
      "step:     9  f: -6.969849586487  gradNorm: 0.001250685\n",
      "step:    10  f: -6.969873905182  gradNorm: 0.001258799\n",
      "step:    11  f: -6.969906330109  gradNorm: 0.001262546\n",
      "step:    12  f: -6.969926357269  gradNorm: 0.001261465\n",
      "step:    13  f: -6.969980239868  gradNorm: 0.001251937\n",
      "step:    14  f: -6.970011234283  gradNorm: 0.001251911\n",
      "step:    15  f: -6.970063686371  gradNorm: 0.001454374\n",
      "step:    16  f: -6.970100402832  gradNorm: 0.003897186\n",
      "step:    17  f: -6.970127582550  gradNorm: 0.004406447\n",
      "step:    18  f: -6.970170497894  gradNorm: 0.002092303\n",
      "step:    19  f: -6.970210075378  gradNorm: 0.002527307\n",
      "step:    20  f: -6.970243930817  gradNorm: 0.001358977\n",
      "step:    21  f: -6.970284938812  gradNorm: 0.001402810\n",
      "step:    22  f: -6.970330238342  gradNorm: 0.001105055\n",
      "step:    23  f: -6.970387458801  gradNorm: 0.001116811\n",
      "step:    24  f: -6.970460414886  gradNorm: 0.001097454\n",
      "step:    25  f: -6.970535278320  gradNorm: 0.001140852\n",
      "step:    26  f: -6.970612049103  gradNorm: 0.001185486\n",
      "step:    27  f: -6.970700263977  gradNorm: 0.001508634\n",
      "step:    28  f: -6.970782279968  gradNorm: 0.004929629\n",
      "step:    29  f: -6.970820426941  gradNorm: 0.007126249\n",
      "step:    30  f: -6.970912933350  gradNorm: 0.002734557\n",
      "step:    31  f: -6.970940113068  gradNorm: 0.004123084\n",
      "step:    32  f: -6.971008300781  gradNorm: 0.002135718\n",
      "step:    33  f: -6.971038818359  gradNorm: 0.003260378\n",
      "step:    34  f: -6.971079349518  gradNorm: 0.002223721\n",
      "step:    35  f: -6.971119403839  gradNorm: 0.001642123\n",
      "step:    36  f: -6.971170425415  gradNorm: 0.001616914\n",
      "step:    37  f: -6.971217632294  gradNorm: 0.001268422\n",
      "step:    38  f: -6.971268177032  gradNorm: 0.001309442\n",
      "step:    39  f: -6.971329689026  gradNorm: 0.001238602\n",
      "step:    40  f: -6.971401691437  gradNorm: 0.001226322\n",
      "step:    41  f: -6.971480846405  gradNorm: 0.001374893\n",
      "step:    42  f: -6.971565246582  gradNorm: 0.001570608\n",
      "step:    43  f: -6.971664428711  gradNorm: 0.003379737\n",
      "step:    44  f: -6.971707820892  gradNorm: 0.005851004\n",
      "step:    45  f: -6.971771717072  gradNorm: 0.004069864\n",
      "step:    46  f: -6.971814155579  gradNorm: 0.003630419\n",
      "step:    47  f: -6.971860885620  gradNorm: 0.002321322\n",
      "step:    48  f: -6.971910476685  gradNorm: 0.002093710\n",
      "step:    49  f: -6.971949100494  gradNorm: 0.002254093\n",
      "step:    50  f: -6.971998214722  gradNorm: 0.002144959\n",
      "step:    51  f: -6.972041606903  gradNorm: 0.001818342\n",
      "step:    52  f: -6.972085952759  gradNorm: 0.001612179\n",
      "step:    53  f: -6.972132205963  gradNorm: 0.001282619\n",
      "step:    54  f: -6.972184658051  gradNorm: 0.001329266\n",
      "step:    55  f: -6.972248554230  gradNorm: 0.001356512\n",
      "step:    56  f: -6.972321510315  gradNorm: 0.001333399\n",
      "step:    57  f: -6.972400665283  gradNorm: 0.001596576\n",
      "step:    58  f: -6.972495079041  gradNorm: 0.001509350\n",
      "step:    59  f: -6.972587585449  gradNorm: 0.002614387\n",
      "step:    60  f: -6.972653865814  gradNorm: 0.005010623\n",
      "step:    61  f: -6.972724437714  gradNorm: 0.004053711\n",
      "step:    62  f: -6.972778320312  gradNorm: 0.004483262\n",
      "step:    63  f: -6.972853660583  gradNorm: 0.001585338\n",
      "step:    64  f: -6.972919464111  gradNorm: 0.001789844\n",
      "step:    65  f: -6.972983837128  gradNorm: 0.001727070\n",
      "step:    66  f: -6.973032951355  gradNorm: 0.002814393\n",
      "step:    67  f: -6.973104476929  gradNorm: 0.001841129\n",
      "step:    68  f: -6.973170280457  gradNorm: 0.001865296\n",
      "step:    69  f: -6.973227500916  gradNorm: 0.002106425\n",
      "step:    70  f: -6.973295688629  gradNorm: 0.001648274\n",
      "step:    71  f: -6.973355770111  gradNorm: 0.002366456\n",
      "step:    72  f: -6.973406314850  gradNorm: 0.003751391\n",
      "step:    73  f: -6.973439216614  gradNorm: 0.003262174\n",
      "step:    74  f: -6.973487377167  gradNorm: 0.001767607\n",
      "step:    75  f: -6.973541736603  gradNorm: 0.002237430\n",
      "step:    76  f: -6.973594188690  gradNorm: 0.001555184\n",
      "step:    77  f: -6.973652362823  gradNorm: 0.001425253\n",
      "step:    78  f: -6.973720073700  gradNorm: 0.001424351\n",
      "step:    79  f: -6.973785877228  gradNorm: 0.001469753\n",
      "step:    80  f: -6.973862171173  gradNorm: 0.001389787\n",
      "step:    81  f: -6.973964691162  gradNorm: 0.001405948\n",
      "step:    82  f: -6.974070072174  gradNorm: 0.001815492\n",
      "step:    83  f: -6.974159717560  gradNorm: 0.003683984\n",
      "step:    84  f: -6.974208831787  gradNorm: 0.006800455\n",
      "step:    85  f: -6.974290847778  gradNorm: 0.002814142\n",
      "step:    86  f: -6.974341392517  gradNorm: 0.003937051\n",
      "step:    87  f: -6.974400997162  gradNorm: 0.003011758\n",
      "step:    88  f: -6.974442005157  gradNorm: 0.003448573\n",
      "step:    89  f: -6.974492549896  gradNorm: 0.002730099\n",
      "step:    90  f: -6.974540233612  gradNorm: 0.001848453\n",
      "step:    91  f: -6.974585533142  gradNorm: 0.001953312\n",
      "step:    92  f: -6.974639415741  gradNorm: 0.001898034\n",
      "step:    93  f: -6.974693775177  gradNorm: 0.001643269\n",
      "step:    94  f: -6.974756240845  gradNorm: 0.001827345\n",
      "step:    95  f: -6.974812030792  gradNorm: 0.001782529\n",
      "step:    96  f: -6.974872112274  gradNorm: 0.001721131\n",
      "step:    97  f: -6.974948406219  gradNorm: 0.001620757\n",
      "step:    98  f: -6.975019454956  gradNorm: 0.002028382\n",
      "step:    99  f: -6.975077629089  gradNorm: 0.003101010\n",
      "step:   100  f: -6.975125789642  gradNorm: 0.005173640\n",
      "step:   200  f: -6.979599952698  gradNorm: 0.003553010\n",
      "step:   300  f: -6.983495235443  gradNorm: 0.001735359\n",
      "step:   400  f: -6.986779689789  gradNorm: 0.003540016\n",
      "step:   500  f: -6.989481925964  gradNorm: 0.002406735\n",
      "step:   600  f: -6.991829395294  gradNorm: 0.001542674\n",
      "step:   700  f: -6.993951797485  gradNorm: 0.001227993\n",
      "step:   800  f: -6.995903491974  gradNorm: 0.001673062\n",
      "step:   900  f: -6.997654914856  gradNorm: 0.001738010\n",
      "step:  1000  f: -6.999222278595  gradNorm: 0.001635809\n",
      "step:  1100  f: -7.000573158264  gradNorm: 0.002068788\n",
      "step:  1200  f: -7.001899242401  gradNorm: 0.001250743\n",
      "step:  1300  f: -7.003108501434  gradNorm: 0.001944281\n",
      "step:  1400  f: -7.004244804382  gradNorm: 0.001214121\n",
      "step:  1500  f: -7.005308628082  gradNorm: 0.001950835\n",
      "step:  1600  f: -7.006322383881  gradNorm: 0.002381530\n",
      "step:  1700  f: -7.007265567780  gradNorm: 0.001260966\n",
      "step:  1800  f: -7.008125782013  gradNorm: 0.001195650\n",
      "step:  1900  f: -7.008956909180  gradNorm: 0.001270996\n",
      "step:  2000  f: -7.009710311890  gradNorm: 0.001696595\n",
      "step:  2100  f: -7.010453701019  gradNorm: 0.001291291\n",
      "step:  2200  f: -7.011121273041  gradNorm: 0.001219446\n",
      "step:  2300  f: -7.011812686920  gradNorm: 0.001496305\n",
      "step:  2400  f: -7.012448310852  gradNorm: 0.001415405\n",
      "step:  2500  f: -7.013076782227  gradNorm: 0.002362676\n",
      "step:  2600  f: -7.013599395752  gradNorm: 0.002915633\n",
      "step:  2700  f: -7.014202117920  gradNorm: 0.001429855\n",
      "step:  2800  f: -7.014668464661  gradNorm: 0.001061075\n",
      "step:  2900  f: -7.015246868134  gradNorm: 0.002487074\n",
      "step:  3000  f: -7.015686988831  gradNorm: 0.001082121\n",
      "step:  3100  f: -7.016177654266  gradNorm: 0.001146430\n",
      "step:  3200  f: -7.016632080078  gradNorm: 0.001116071\n",
      "step:  3300  f: -7.017037868500  gradNorm: 0.001061213\n",
      "step:  3400  f: -7.017476558685  gradNorm: 0.001010605\n",
      "step:  3500  f: -7.017915248871  gradNorm: 0.003154543\n",
      "step:  3600  f: -7.018311500549  gradNorm: 0.001138881\n",
      "step:  3700  f: -7.018720149994  gradNorm: 0.002367374\n",
      "step:  3800  f: -7.019109725952  gradNorm: 0.001124459\n",
      "step:  3900  f: -7.019416332245  gradNorm: 0.000981232\n",
      "step:  4000  f: -7.019815921783  gradNorm: 0.000965748\n",
      "step:  4100  f: -7.020160198212  gradNorm: 0.001405648\n",
      "step:  4200  f: -7.020514011383  gradNorm: 0.001371066\n",
      "step:  4300  f: -7.020816326141  gradNorm: 0.001883529\n",
      "step:  4400  f: -7.021173477173  gradNorm: 0.001109643\n",
      "step:  4500  f: -7.021427631378  gradNorm: 0.001135155\n",
      "step:  4600  f: -7.021792411804  gradNorm: 0.001597734\n",
      "step:  4700  f: -7.022118091583  gradNorm: 0.000974464\n",
      "step:  4800  f: -7.022402286530  gradNorm: 0.001063102\n",
      "step:  4900  f: -7.022700786591  gradNorm: 0.003165171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  4999  f: -7.022972106934  gradNorm: 0.001575192\n",
      " took 27249.8464 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(1):\n",
    "    print(\"Optimization restart: {}\".format(i))\n",
    "    xrestart = opt_energyrc(steps=5000,num_basis=7168, restart=True)\n",
    "print(\" took {:.4f} seconds \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch10",
   "language": "python",
   "name": "pytorch10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
