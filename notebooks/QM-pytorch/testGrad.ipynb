{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  0.4.0\n",
      "CUDA available:  True\n",
      "CUDA version:  9.1.85\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = th.float64\n",
    "device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# return the lower triangle of A in column order i.e. vech(A)\n",
    "def vech(A):\n",
    "    count = 0\n",
    "    c = A.shape[0]\n",
    "    v = th.zeros(c * (c + 1) // 2,)\n",
    "    for j in range(c):\n",
    "        for i in range(j,c):\n",
    "            v[count] = A[i,j]\n",
    "            count += 1\n",
    "    return th.tensor(v , device=device, dtype=dtype)\n",
    "\n",
    "# vech2L   create lower triangular matrix L from vechA\n",
    "def vech2L(v,n):\n",
    "    count = 0\n",
    "    L = th.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[i,j]=v[count]\n",
    "            count += 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3;\n",
    "vechLk = th.tensor([  1.00000039208682, \n",
    "              0.02548044275764261, \n",
    "              0.3525161612610669,\n",
    "              1.6669144815242515,\n",
    "              0.9630555318946559,\n",
    "              1.8382882034659822 ], device=device, dtype=dtype, requires_grad=True);\n",
    "\n",
    "vechLl = th.tensor([  1.3353550436464964,\n",
    "               0.9153272033682132,\n",
    "               0.7958636766525028,\n",
    "               1.8326931436447955,\n",
    "               0.3450426931160630,\n",
    "               1.8711839323167831 ], device=device, dtype=dtype, requires_grad=True);\n",
    "Sym = th.tensor([[0,0,1],\n",
    "                [0,1,0],\n",
    "                [1,0,0]], device=device, dtype=dtype, requires_grad=False);\n",
    "#Sym = th.tensor([[1,0,0],\n",
    "#                [0,1,0],\n",
    "#                [0,0,1]], device=device, dtype=dtype);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5334, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Lk = vech2L(vechLk,n);\n",
    "Ll = vech2L(vechLl,n);\n",
    "\n",
    "# apply symmetry projection on Ll\n",
    "\n",
    "# th.t() is shorthand for th.transpose(X, 0,1)\n",
    "PLl = th.t(Sym) @ Ll;\n",
    "\n",
    "# build Ak, Al, Akl, invAkl, invAk, invAl\n",
    "\n",
    "Ak = Lk@th.t(Lk);\n",
    "Al = PLl@th.t(PLl);\n",
    "Akl = Ak+Al\n",
    "\n",
    "skl = 2**(3*n/2) * th.sqrt( th.pow(th.abs(th.det(Lk))*th.abs(th.det(Ll))/th.det(Akl) ,3) )\n",
    "print(skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4898,  0.0786, -0.0560,  0.1179, -0.1113, -0.1632], dtype=torch.float64),)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.autograd.grad(skl, vechLk, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3198, -0.0666, -0.1495, -0.0751, -0.0352, -0.1917], dtype=torch.float64),)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.autograd.grad(skl, vechLl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
