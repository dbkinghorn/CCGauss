{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  1.1.0\n",
      "CUDA available:  True\n",
      "CUDA version:  10.0.130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__ )\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "n = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(n,n).astype('float64')\n",
    "B = np.random.randn(n,n).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 35.13306379318237 seconds \n",
      " norm =  2828463.0201447452\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "nrm = np.linalg.norm(A@B)\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "print(\" norm = \",nrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tA = torch.randn(n,n, dtype = torch.float64)\n",
    "tB = torch.randn(n,n, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 16.623844861984253 seconds \n",
      " norm =  tensor(2828092.3386, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tnrm = (tA@tB).norm()\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "print(\" norm = \",tnrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gA = torch.randn(n,n, device=\"cuda\")\n",
    "gB = torch.randn(n,n, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.17258548736572266 seconds \n",
      " norm =  tensor(1.00000e+06 *\n",
      "       1.0001, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gnrm = (gA@gB).norm()\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "print(\" norm = \",gnrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(4,4).astype('float32')\n",
    "X = np.random.randn(4,4).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5049461 , -0.19887437,  0.18442628, -0.68315524],\n",
       "       [-0.9890729 , -0.8097865 , -0.17070463, -0.24591489],\n",
       "       [ 1.0504804 ,  2.2784846 , -0.61209446,  0.8285161 ],\n",
       "       [ 1.1353166 , -0.01387051,  0.11121433, -0.93461305]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.79756254,  0.17181225, -0.96386087,  0.3195454 ],\n",
       "       [ 0.13475977, -0.10574374,  1.1533258 ,  0.6280106 ],\n",
       "       [-0.5517436 ,  0.81820333,  0.34025642,  1.4709991 ],\n",
       "       [ 0.20693423, -2.212612  ,  0.38112938,  0.67755526]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.967725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(A@X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9677243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrmAX = np.sqrt(np.trace(np.transpose(A@X)@(A@X)))\n",
    "nrmAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5049, -0.1989,  0.1844, -0.6832],\n",
       "        [-0.9891, -0.8098, -0.1707, -0.2459],\n",
       "        [ 1.0505,  2.2785, -0.6121,  0.8285],\n",
       "        [ 1.1353, -0.0139,  0.1112, -0.9346]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tA = torch.tensor(A, requires_grad=True)\n",
    "tA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7976,  0.1718, -0.9639,  0.3195],\n",
       "        [ 0.1348, -0.1057,  1.1533,  0.6280],\n",
       "        [-0.5517,  0.8182,  0.3403,  1.4710],\n",
       "        [ 0.2069, -2.2126,  0.3811,  0.6776]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX = torch.tensor(X, requires_grad=True)\n",
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9677)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrmtAX = (tA@tX).norm()\n",
    "nrmtAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42761004, -0.19405963,  0.05810442,  0.5713776 ],\n",
       "       [-0.1298413 , -1.2209185 ,  0.8133703 ,  0.8767274 ],\n",
       "       [-0.04326902,  0.39604086, -0.23749249, -0.1535332 ],\n",
       "       [ 0.1609802 , -1.0779235 ,  0.55445796,  0.38704368]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnrmAX = (A.transpose()@A@X)/nrmAX\n",
    "dnrmAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4276, -0.1941,  0.0581,  0.5714],\n",
       "         [-0.1298, -1.2209,  0.8134,  0.8767],\n",
       "         [-0.0433,  0.3960, -0.2375, -0.1535],\n",
       "         [ 0.1610, -1.0779,  0.5545,  0.3870]]),)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(nrmtAX, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmtAX.backward(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0611, -1.6265,  0.0358,  0.5970],\n",
       "        [-0.0055, -0.8895,  0.2976,  1.0967],\n",
       "        [-0.0141,  0.1361, -0.0813, -0.2394],\n",
       "        [ 0.0570,  0.6177,  0.2157,  0.4246]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnrmtAX = tX.grad\n",
    "dnrmtAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5049, -0.1989,  0.1844, -0.6832],\n",
       "        [-0.9891, -0.8098, -0.1707, -0.2459],\n",
       "        [ 1.0505,  2.2785, -0.6121,  0.8285],\n",
       "        [ 1.1353, -0.0139,  0.1112, -0.9346]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gA = Variable(tA.cuda(), requires_grad=True)\n",
    "gA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4713, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrmgA = gA.norm()\n",
    "nrmgA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmgA.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1455, -0.0573,  0.0531, -0.1968],\n",
       "        [-0.2849, -0.2333, -0.0492, -0.0708],\n",
       "        [ 0.3026,  0.6564, -0.1763,  0.2387],\n",
       "        [ 0.3271, -0.0040,  0.0320, -0.2692]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnrmgA = gA.grad\n",
    "dnrmgA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6154,  0.0762],\n",
       "        [-0.9105,  0.3103]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tA = torch.randn(2,2)\n",
    "tA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tI = torch.eye(3)\n",
    "tI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6153514 ,  0.        ,  0.        ,  0.07615926,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.6153514 ,  0.        ,  0.        ,  0.07615926,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.6153514 ,  0.        ,  0.        ,\n",
       "         0.07615926],\n",
       "       [-0.9105107 , -0.        , -0.        ,  0.3102524 ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.        , -0.9105107 , -0.        ,  0.        ,  0.3102524 ,\n",
       "         0.        ],\n",
       "       [-0.        , -0.        , -0.9105107 ,  0.        ,  0.        ,\n",
       "         0.3102524 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(tA,tI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-openblas",
   "language": "python",
   "name": "pytorch-openblas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
