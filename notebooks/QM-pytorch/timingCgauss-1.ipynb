{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Timing the bits ... Cgauss in PyTorch\n",
    "Correlated gaussian basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "import time\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device:  cuda:0\n",
      "PyTorch version:  0.4.1\n",
      "CUDA available:  True\n",
      "CUDA version:  9.0.176\n",
      "CUDA device: TITAN V\n"
     ]
    }
   ],
   "source": [
    "dtype = th.float64\n",
    "\n",
    "gpuid = 0\n",
    "device = th.device(\"cuda:\"+ str(gpuid))\n",
    "#device = th.device(\"cpu\")\n",
    "\n",
    "print(\"Execution device: \",device)\n",
    "print(\"PyTorch version: \", th.__version__ )\n",
    "print(\"CUDA available: \", th.cuda.is_available())\n",
    "print(\"CUDA version: \", th.version.cuda)\n",
    "print(\"CUDA device:\", th.cuda.get_device_name(gpuid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def vech2L(v,n):\n",
    "    count = 0\n",
    "    L = th.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[i,j]=v[count]\n",
    "            count = count + 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)\n",
    "\n",
    "# batched vech2L input is \"X\" as V nb x n(n+1)/2\n",
    "def bvech2L(V,nb,n):\n",
    "    count = 0\n",
    "    L = th.zeros((nb,n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j,n):\n",
    "            L[...,i,j]=V[...,count]\n",
    "            count = count + 1\n",
    "    return th.tensor(L , device=device, dtype=dtype)\n",
    "\n",
    "# Batched Cholesky decomp\n",
    "def cholesky(A):\n",
    "    L = th.zeros_like(A)\n",
    "    \n",
    "    for i in range(A.shape[-1]):\n",
    "        for j in range(i+1):\n",
    "            s = 0.0\n",
    "            for k in range(j):\n",
    "                s = s + L[...,i,k].clone() * L[...,j,k].clone()\n",
    "            \n",
    "            L[...,i,j] = th.sqrt(A[...,i,i] - s) if (i == j) else \\\n",
    "                      (1.0 / L[...,j,j].clone() * (A[...,i,j] - s))\n",
    "    return th.tensor(L , device=device, dtype=dtype)\n",
    "\n",
    "# Batched inverse of lower triangular matrices \n",
    "def inverseL(L):\n",
    "    n = L.shape[-1]\n",
    "    invL = th.zeros_like(L)\n",
    "    for j in range(0,n):\n",
    "        invL[...,j,j] = 1.0/L[...,j,j]\n",
    "        for i in range(j+1,n):\n",
    "            S = 0.0\n",
    "            for k in range(i+1):\n",
    "                S = S - L[...,i,k]*invL[...,k,j].clone()\n",
    "            invL[...,i,j] = S/L[...,i,i]\n",
    "\n",
    "    return th.tensor(invL , device=device, dtype=dtype)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_energyrc(x,n,nb,Mass,Qmat,Sym,symc):\n",
    "    \n",
    "# Timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    nx = len(x);\n",
    "    nn = int(n*(n+1)/2);\n",
    "    nsym = len(symc);\n",
    "    #nsym = 1\n",
    "    \n",
    "    # extract linear coefs \"eigen vector\"\n",
    "    c = th.tensor(x[-nb:], device=device, dtype=dtype);\n",
    "    # reshape non-linear variables for easier indexing\n",
    "    X = th.reshape(x[:nb*nn], (nb,nn))\n",
    "    \n",
    "    # generate tensor of lower triangular matrices from X\n",
    "    # these are the non-linear parameters of the basis set\n",
    "    L = th.zeros((nb,n,n), device=device, dtype=dtype)\n",
    "    L = bvech2L(X,nb,n)\n",
    "# End-Timing    \n",
    "    print(\" {:20} {:.6f} seconds \".format('data init:', time.time() - start_time))\n",
    "# Timing\n",
    "    start_time = time.time()    \n",
    "    # get the determinates for L |L| is the product of diag elements\n",
    "    detL = th.abs(th.prod(th.diagonal(L, offset=0, dim1=-1, dim2=-2),1))\n",
    "    \n",
    "    # create the tensor of matrix products of the L matrices AKL = L x Ltranspose\n",
    "    AK = th.matmul(L,th.transpose(L, 1, 2))\n",
    "    #AKrepT = th.transpose(AK.repeat((nb,1,1,1)), 0,1)\n",
    "# End-Timing    \n",
    "    print(\" {:20} {:.6f} seconds \".format('detL and AK gen', time.time() - start_time))\n",
    "    \n",
    "    # Initialize H T V and S matrices\n",
    "    # H = T + V, we are solving (H-ES)c = 0 for E (energy)\n",
    "    H = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    S = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    T = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    V = th.zeros((nb,nb), device=device, dtype=dtype);\n",
    "    \n",
    "\n",
    "    # outer loop is over symmetry terms, the matrices are summed over these sym terms\n",
    "    for k in range(0,nsym):\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        P = Sym[k,:,:]\n",
    "        # symetry projection is applied only to \"ket\" this constructs AL\n",
    "        AL = th.matmul(th.t(P), th.matmul(AK,P))\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('gen AL sym took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        # Akl = Ak + Al \n",
    "        AKL = th.zeros((nb,nb,n,n), device=device, dtype=dtype)\n",
    "        #for i in range(nb):\n",
    "        #    for j in range(nb):\n",
    "        #        #AKL[i,j] =  th.add(AK[i], AL[j])\n",
    "        #        AKL[i,j] =  AK[i] + AL[j]\n",
    "        AKL = AL.repeat((nb,1,1,1)) + th.transpose(AK.repeat((nb,1,1,1)), 0,1)\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('gen AKL loop took', time.time() - start_time))\n",
    "\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        # get the Cholesky decomp of all Akl martices\n",
    "        cholAKL = cholesky(AKL)\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('cholAKL took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        # get determinates of AKL from diags |Akl|= |Lk|**2\n",
    "        detAKL = th.prod(th.diagonal(cholAKL, offset=0, dim1=-1, dim2=-2),-1)**2\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('detAKL took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        # compute inverses of lower tringular matrices in cholAKL\n",
    "        invLKL = inverseL(cholAKL)\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('invLKL took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        # inverses Akl^-1 = Lkl' x Lkl\n",
    "        invAKL = th.matmul(th.transpose(invLKL, dim0=-1, dim1=-2),invLKL)\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('invAKL sym took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        # get terms needed for potential energy V\n",
    "        # RIJ.shape = nb,nb,n,n\n",
    "        RIJ = th.zeros_like(AKL, device=device, dtype=dtype)\n",
    "        # 1/rij i~=j\n",
    "        for j in range(0,n-1):\n",
    "            for i in range(j+1,n):\n",
    "                tmp2 = invAKL[...,i,i] + invAKL[...,j,j] - 2*invAKL[...,i,j];\n",
    "                RIJ[...,i,j] = th.rsqrt(tmp2)\n",
    "\n",
    "        # 1/rij i=j\n",
    "        for i in range(0,n):\n",
    "            RIJ[...,i,i] = th.rsqrt(invAKL[...,i,i])\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('gen RIJ took', time.time() - start_time))\n",
    "\n",
    "        # MATRIX ELEMENTS\n",
    "# Timing\n",
    "        start_time = time.time()        \n",
    "        # Overlap: (normalized)\n",
    "        # Skl = 2^3n/2 (||Lk|| ||Ll||/|AKL|)^3/2\n",
    "        SKL = 2**(n*1.5) * th.sqrt( th.pow(th.ger(detL, detL)/detAKL ,3) );\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('Overlap: took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        # Kinetic energy\n",
    "        #TKL = SKL*(6*th.trace(Mass@Ak@invAkl@Al)) = skl*(6*th.sum(Mass*(Ak@invAkl@Al)))\n",
    "\n",
    "        Tmat = th.zeros_like(invAKL)\n",
    "        #for i in range(nb):\n",
    "        #    for j in range(nb):\n",
    "        #        Tmat[i,j] = (AK[i]@invAKL[i,j]@AL[j])\n",
    "        \n",
    "        Tmat = th.matmul(th.transpose(AK.repeat((nb,1,1,1)), 0,1), th.matmul(invAKL,AL))\n",
    "        TKL = 6*SKL*th.sum(Mass*Tmat, dim=(-2,-1))\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('Kinetic: took', time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        # potential energy\n",
    "        TWOoSqrtPI = 1.1283791670955126 # 2/sqrt(pi)\n",
    "        \n",
    "        VKL = TWOoSqrtPI*SKL*th.sum(RIJ*Qmat, dim=(-2,-1))\n",
    "# End-Timing    \n",
    "        print(\" {:20} {:.6f} seconds \".format('Potential: took', time.time() - start_time))\n",
    "    \n",
    "        # accumulate matrices over sym terms\n",
    "        S = S + symc[k]*SKL\n",
    "        T = T + symc[k]*TKL\n",
    "        V = V + symc[k]*VKL\n",
    "        \n",
    "    # Hamiltonian\n",
    "    H = T + V\n",
    "# Timing\n",
    "    start_time = time.time()    \n",
    "    # complete lower triangle of H and S\n",
    "    for i in range(0,nb):\n",
    "        for j in range(i+1,nb):\n",
    "            H[j,i] = H[i,j]\n",
    "            S[j,i] = S[i,j]\n",
    "    #        #H[i,j] = H[j,i];\n",
    "    #        #S[i,j] = S[j,i];\n",
    "    #H = th.triu(H,1)+th.t(th.triu(H))\n",
    "    #S = th.triu(S,1)+th.t(th.triu(S))\n",
    "# End-Timing    \n",
    "    print(\" {:20} {:.6f} seconds \".format('Complete H and S', time.time() - start_time))\n",
    "    \n",
    "# Timing\n",
    "    start_time = time.time()\n",
    "    # compute Raylie quotent (it is the smallest energy eigen value when minimized over c)\n",
    "    cHc = c@H@c;\n",
    "    cSc = c@S@c;\n",
    "    eng = cHc/cSc;\n",
    "# End-Timing    \n",
    "    print(\" {:20} {:.6f} seconds \".format('Energy:', time.time() - start_time))\n",
    "    return eng           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_energyrc():\n",
    "    \n",
    "    #\n",
    "    # Li BO setup\n",
    "    #\n",
    "    n=3;\n",
    "    \n",
    "    Mass = th.tensor([[0.5, 0.0, 0.0],\n",
    "                     [0.0, 0.5, 0.0],\n",
    "                     [0.0, 0.0, 0.5]], device=device, dtype=dtype);\n",
    "    \n",
    "    Charge = th.tensor([-3, 1, 1, -3, 1, -3], device=device, dtype=dtype);\n",
    "    Charge = vech2L(Charge,n)\n",
    "    \n",
    "    # symmetry projection terms\n",
    "    Sym = th.zeros((6,3,3), device=device, dtype=dtype)\n",
    "    # (1)(2)(3)\n",
    "    Sym[0,:,:] = th.tensor([[1,0,0],[0,1,0],[0,0,1]], device=device, dtype=dtype);\n",
    "    # (12)\n",
    "    Sym[1,:,:] = th.tensor([[0,1,0],[1,0,0],[0,0,1]], device=device, dtype=dtype);\n",
    "    # (13)\n",
    "    Sym[2,:,:] = th.tensor([[0,0,1],[0,1,0],[1,0,0]], device=device, dtype=dtype);\n",
    "    # (23)\n",
    "    Sym[3,:,:] = th.tensor([[1,0,0],[0,0,1],[0,1,0]], device=device, dtype=dtype);\n",
    "    # (123)\n",
    "    Sym[4,:,:] = th.tensor([[0,1,0],[0,0,1],[1,0,0]], device=device, dtype=dtype);\n",
    "    # (132)\n",
    "    Sym[5,:,:] = th.tensor([[0,0,1],[1,0,0],[0,1,0]], device=device, dtype=dtype);\n",
    "\n",
    "    # coeff's\n",
    "    symc = th.tensor([4.0,4.0,-2.0,-2.0,-2.0,-2.0], device=device, dtype=dtype);\n",
    "\n",
    "    # Sample parameters should return energy of -7.3615\n",
    "    xvechL=th.tensor([\n",
    "     1.6210e+00,\n",
    "    -2.1504e-01,\n",
    "     9.0755e-01,\n",
    "     9.7866e-01,\n",
    "    -2.8418e-01,\n",
    "    -3.5286e+00,\n",
    "    -3.3045e+00,\n",
    "    -4.5036e+00,\n",
    "    -3.2116e-01,\n",
    "    -7.1901e-02,\n",
    "     1.5167e+00,\n",
    "    -8.4489e-01,\n",
    "    -2.1377e-01,\n",
    "    -3.6127e-03,\n",
    "    -5.3774e-03,\n",
    "    -2.1263e+00,\n",
    "    -2.5191e-01,\n",
    "     2.1235e+00,\n",
    "    -2.1396e-01,\n",
    "    -1.4084e-03,\n",
    "    -1.0092e-02,\n",
    "     4.5349e+00,\n",
    "     9.4837e-03,\n",
    "     1.1225e+00,\n",
    "    -2.1315e-01,\n",
    "     5.8451e-02,\n",
    "    -4.9410e-03,\n",
    "     5.0853e+00,\n",
    "     7.3332e-01,\n",
    "     5.0672e+00,\n",
    "    -2.1589e-01,\n",
    "    -6.8986e-03,\n",
    "    -1.4310e-02,\n",
    "     1.5979e+00,\n",
    "     3.3946e-02,\n",
    "    -8.7965e-01,\n",
    "    -1.1121e+00,\n",
    "    -2.1903e-03,\n",
    "    -4.6925e-02,\n",
    "     2.1457e-01,\n",
    "     3.3045e-03,\n",
    "     4.5120e+00,\n",
    "    -2.1423e-01,\n",
    "    -1.6493e-02,\n",
    "    -2.3429e-03,\n",
    "    -8.6715e-01,\n",
    "    -6.7070e-02,\n",
    "     1.5998e+00\n",
    "     ], device=device, dtype=dtype, requires_grad=False)\n",
    "    \n",
    "    evec = th.tensor([\n",
    "      -6.0460e-02,\n",
    "       7.7708e-05,\n",
    "       1.6152e+00,\n",
    "       9.5443e-01,\n",
    "       1.1771e-01,\n",
    "       3.2196e+00,\n",
    "       9.6344e-01,\n",
    "       3.1398e+00\n",
    "    ], device=device, dtype=dtype, requires_grad=False)\n",
    "    \n",
    "    # uncomment following lines to test above \n",
    "    #nb=8\n",
    "    #x1 = th.tensor(th.cat((xvechL,evec)), device=device, dtype=dtype, requires_grad=True)\n",
    "    #energy = b_energyrc(x1,n,nb,Mass,Charge,Sym,symc) \n",
    "    #print(energy) # should be -7.3615\n",
    "    #return x1\n",
    "    \n",
    "    # random start point\n",
    "    nb=512;\n",
    "    th.manual_seed(42)\n",
    "    x1 = th.randn(int(nb*n*(n+1)/2 + nb) , device=device, dtype=dtype, requires_grad=True)\n",
    "    \n",
    "    # start from a restart value\n",
    "    #x1 = xrestart\n",
    "    #print(energy)\n",
    "    #return x1\n",
    "    \n",
    "    # Do the Optimization\n",
    "    #optimizer = th.optim.LBFGS([x1])\n",
    "    optimizer = th.optim.Adadelta([x1], lr=2.0)\n",
    "    #optimizer = th.optim.Adam([x1], lr=0.5)\n",
    "    \n",
    "    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True,patience=2, factor=0.5)\n",
    "    \n",
    "    for i in range(1):\n",
    "        optimizer.zero_grad()\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        loss = b_energyrc(x1,n,nb,Mass,Charge,Sym,symc)\n",
    "# End-Timing    \n",
    "        print(\" Tot Energy: took {} seconds \".format(time.time() - start_time))\n",
    "# Timing\n",
    "        start_time = time.time()\n",
    "        loss.backward()\n",
    "# End-Timing    \n",
    "        print(\" Gradient: took {} seconds \".format(time.time() - start_time))\n",
    "        #def closure():\n",
    "        #    return b_energyrc(x1,n,nb,Mass,Charge,Sym,symc)\n",
    "        #optimizer.step(closure)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        print('step: {} f: {} gradNorm: {}'.format(i, loss, th.norm(x1.grad)))\n",
    "    \n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data init:           0.001123 seconds \n",
      " detL and AK gen      0.000952 seconds \n",
      " gen AL sym took      0.000296 seconds \n",
      " gen AKL loop took    0.000510 seconds \n",
      " cholAKL took         0.002221 seconds \n",
      " detAKL took          0.000479 seconds \n",
      " invLKL took          0.002255 seconds \n",
      " invAKL sym took      0.000365 seconds \n",
      " gen RIJ took         0.001510 seconds \n",
      " Overlap: took        0.000445 seconds \n",
      " Kinetic: took        0.000752 seconds \n",
      " Potential: took      0.000397 seconds \n",
      " gen AL sym took      0.000148 seconds \n",
      " gen AKL loop took    0.000351 seconds \n",
      " cholAKL took         0.001153 seconds \n",
      " detAKL took          0.000276 seconds \n",
      " invLKL took          0.001115 seconds \n",
      " invAKL sym took      0.000231 seconds \n",
      " gen RIJ took         0.000740 seconds \n",
      " Overlap: took        0.000217 seconds \n",
      " Kinetic: took        0.000531 seconds \n",
      " Potential: took      0.000273 seconds \n",
      " gen AL sym took      0.000128 seconds \n",
      " gen AKL loop took    0.000315 seconds \n",
      " cholAKL took         0.001074 seconds \n",
      " detAKL took          0.000257 seconds \n",
      " invLKL took          0.001120 seconds \n",
      " invAKL sym took      0.000207 seconds \n",
      " gen RIJ took         0.000707 seconds \n",
      " Overlap: took        0.000206 seconds \n",
      " Kinetic: took        0.000531 seconds \n",
      " Potential: took      0.000205 seconds \n",
      " gen AL sym took      0.000090 seconds \n",
      " gen AKL loop took    0.000308 seconds \n",
      " cholAKL took         0.000973 seconds \n",
      " detAKL took          0.000265 seconds \n",
      " invLKL took          0.001003 seconds \n",
      " invAKL sym took      0.000226 seconds \n",
      " gen RIJ took         0.000685 seconds \n",
      " Overlap: took        0.000203 seconds \n",
      " Kinetic: took        0.000511 seconds \n",
      " Potential: took      0.000270 seconds \n",
      " gen AL sym took      0.000087 seconds \n",
      " gen AKL loop took    0.000290 seconds \n",
      " cholAKL took         0.000942 seconds \n",
      " detAKL took          0.000240 seconds \n",
      " invLKL took          0.000990 seconds \n",
      " invAKL sym took      0.000237 seconds \n",
      " gen RIJ took         0.000688 seconds \n",
      " Overlap: took        0.000212 seconds \n",
      " Kinetic: took        0.000409 seconds \n",
      " Potential: took      0.000265 seconds \n",
      " gen AL sym took      0.000086 seconds \n",
      " gen AKL loop took    0.000299 seconds \n",
      " cholAKL took         0.000915 seconds \n",
      " detAKL took          0.000222 seconds \n",
      " invLKL took          0.000935 seconds \n",
      " invAKL sym took      0.000216 seconds \n",
      " gen RIJ took         0.000629 seconds \n",
      " Overlap: took        0.000292 seconds \n",
      " Kinetic: took        0.000480 seconds \n",
      " Potential: took      0.000278 seconds \n",
      " Complete H and S     5.018198 seconds \n",
      " Energy:              0.000585 seconds \n",
      " Tot Energy: took 5.0590784549713135 seconds \n",
      " Gradient: took 20.747183799743652 seconds \n",
      "step: 0 f: 3.29469524688084 gradNorm: 6.23065651735314\n",
      " took 25.81410050392151 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xrestart = opt_energyrc()\n",
    "print(\" took {} seconds \".format(time.time() - start_time))\n",
    "#cProfile.run('xprof = opt_energyrc()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th.save(xrestart, 'Libo-nb128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xrestart = th.load('Libo-nb64-7.450.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
